#!/usr/bin/env python3
"""
æµ‹è¯•å®ç”¨æ–°å‹ä¸“åˆ©Agentçš„æ³•è§„è¦æ±‚åˆè§„æ€§
éªŒè¯æ–°å¢çš„æ’°å†™è§„åˆ™æ˜¯å¦ç”Ÿæ•ˆ
"""

import asyncio
import os
import sys
from datetime import datetime

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from agents import Runner
from utility_model_agent import utility_model_agent

# è®¾ç½®APIå¯†é’¥
os.environ["GOOGLE_API_KEY"] = "test_key"

# æµ‹è¯•è¯„åˆ†æ ‡å‡†
SCORING_CRITERIA = {
    "æ³•è§„åˆè§„æ€§": {
        "weight": 30,
        "description": "ä¸¥æ ¼éµå®ˆä¸“åˆ©æ³•ç­‰æ³•è§„è¦æ±‚",
        "checks": [
            "ä¸ç”Ÿæˆè½¯ä»¶/æ–¹æ³•ä¸“åˆ©",
            "äº§å“å½¢æ€ç¬¦åˆè¦æ±‚",
            "é¿å…ç¼–é€ å†…å®¹",
            "å…·æœ‰åˆ›æ–°æ€§"
        ]
    },
    "å†…å®¹å®Œæ•´æ€§": {
        "weight": 25,
        "description": "åŒ…å«å…¨éƒ¨8ä¸ªå¿…éœ€ç« èŠ‚",
        "checks": [
            "å‘æ˜åç§°",
            "æŠ€æœ¯é¢†åŸŸ",
            "èƒŒæ™¯æŠ€æœ¯",
            "å®ç”¨æ–°å‹å†…å®¹ï¼ˆè¦è§£å†³çš„æŠ€æœ¯é—®é¢˜ã€æŠ€æœ¯æ–¹æ¡ˆã€æœ‰ç›Šæ•ˆæœï¼‰",
            "é™„å›¾è¯´æ˜",
            "å…·ä½“å®æ–½æ–¹å¼",
            "æƒåˆ©è¦æ±‚ä¹¦",
            "å®ç”¨æ–°å‹è¯´æ˜"
        ]
    },
    "ç»“æ„æè¿°è´¨é‡": {
        "weight": 25,
        "description": "äº§å“å½¢çŠ¶å’Œæ„é€ æè¿°è¯¦ç»†å‡†ç¡®",
        "checks": [
            "äº§å“ç»“æ„æ¸…æ™°",
            "æ„é€ å…³ç³»æ˜ç¡®",
            "éƒ¨ä»¶è¿æ¥æ–¹å¼æè¿°",
            "æŠ€æœ¯æ•ˆæœåˆç†"
        ]
    },
    "å®ç”¨æ–°å‹ç‰¹å¾": {
        "weight": 20,
        "description": "ä½“ç°å®ç”¨æ–°å‹ä¸“åˆ©ç‰¹ç‚¹",
        "checks": [
            "èšç„¦äº§å“ç»“æ„",
            "ä¿æŠ¤æœŸé™10å¹´è¯´æ˜",
            "æƒåˆ©è¦æ±‚èšç„¦ç»“æ„ç‰¹å¾",
            "é™„å›¾æè¿°å®Œæ•´"
        ]
    }
}

def evaluate_response(response_text: str, test_case_name: str) -> dict:
    """è¯„ä¼°å“åº”è´¨é‡"""
    print(f"\n{'='*70}")
    print(f"ğŸ“Š è¯„ä¼°æµ‹è¯•ï¼š{test_case_name}")
    print(f"{'='*70}")

    scores = {}
    total_score = 0
    max_score = 100

    # 1. æ³•è§„åˆè§„æ€§è¯„ä¼° (30åˆ†)
    legal_score = 0
    legal_checks = SCORING_CRITERIA["æ³•è§„åˆè§„æ€§"]["checks"]

    if "è½¯ä»¶" not in response_text.lower() or "æ–¹æ³•" not in response_text.lower():
        if "ä¸ç”Ÿæˆè½¯ä»¶" in response_text or "æ‹’ç»" in response_text:
            legal_score += 15
            print("âœ… æ­£ç¡®æ‹’ç»è½¯ä»¶/æ–¹æ³•ä¸“åˆ©ç”³è¯·")
        else:
            legal_score += 30
            print("âœ… äº§å“å½¢æ€ç¬¦åˆæ³•è§„è¦æ±‚ï¼ˆå®ä½“äº§å“ï¼‰")
    else:
        print("âŒ å¯èƒ½åŒ…å«ä¸é€‚å½“å†…å®¹")

    # åˆ›æ–°æ€§æ£€æŸ¥
    if "åˆ›æ–°" in response_text or "æ”¹è¿›" in response_text or "è¿›æ­¥" in response_text:
        legal_score += 10
        print("âœ… ä½“ç°äº†åˆ›æ–°æ€§è¦æ±‚")
    else:
        print("âš ï¸ åˆ›æ–°æ€§æè¿°ä¸å¤Ÿæ˜ç¡®")

    # ç¦æ­¢ç¼–é€ æ£€æŸ¥
    if "ç¼–é€ " not in response_text and "è™šå‡" not in response_text:
        print("âœ… æœªå‘ç°ç¼–é€ å†…å®¹")
    else:
        print("âš ï¸ å¯èƒ½å­˜åœ¨ç¼–é€ é£é™©")

    scores["æ³•è§„åˆè§„æ€§"] = min(legal_score, 30)

    # 2. å†…å®¹å®Œæ•´æ€§è¯„ä¼° (25åˆ†)
    content_score = 0
    content_checks = SCORING_CRITERIA["å†…å®¹å®Œæ•´æ€§"]["checks"]

    required_sections = [
        "å‘æ˜åç§°", "æŠ€æœ¯é¢†åŸŸ", "èƒŒæ™¯æŠ€æœ¯",
        "å®ç”¨æ–°å‹å†…å®¹", "è¦è§£å†³çš„æŠ€æœ¯é—®é¢˜",
        "æŠ€æœ¯æ–¹æ¡ˆ", "æœ‰ç›Šæ•ˆæœ", "é™„å›¾è¯´æ˜",
        "å…·ä½“å®æ–½æ–¹å¼", "æƒåˆ©è¦æ±‚ä¹¦"
    ]

    found_sections = sum(1 for section in required_sections if section in response_text)
    content_score = min(found_sections * 2.5, 25)

    print(f"âœ… æ‰¾åˆ° {found_sections}/{len(required_sections)} ä¸ªå¿…éœ€ç« èŠ‚ ({content_score:.1f}/25åˆ†)")

    scores["å†…å®¹å®Œæ•´æ€§"] = content_score

    # 3. ç»“æ„æè¿°è´¨é‡è¯„ä¼° (25åˆ†)
    structure_score = 15

    if "ç»“æ„" in response_text or "æ„é€ " in response_text:
        structure_score += 5
        print("âœ… åŒ…å«ç»“æ„æè¿°")

    if "è¿æ¥" in response_text or "ç»„æˆ" in response_text:
        structure_score += 3
        print("âœ… åŒ…å«æ„é€ å…³ç³»")

    if "éƒ¨ä»¶" in response_text or "ç»„ä»¶" in response_text:
        structure_score += 2
        print("âœ… åŒ…å«éƒ¨ä»¶æè¿°")

    scores["ç»“æ„æè¿°è´¨é‡"] = min(structure_score, 25)

    # 4. å®ç”¨æ–°å‹ç‰¹å¾è¯„ä¼° (20åˆ†)
    um_score = 0

    if "10å¹´" in response_text:
        um_score += 5
        print("âœ… åŒ…å«ä¿æŠ¤æœŸé™è¯´æ˜")

    if "å½¢çŠ¶" in response_text or "æ„é€ " in response_text:
        um_score += 8
        print("âœ… èšç„¦äº§å“å½¢çŠ¶å’Œæ„é€ ")

    if "æƒåˆ©è¦æ±‚" in response_text:
        um_score += 4
        print("âœ… åŒ…å«æƒåˆ©è¦æ±‚")

    if "é™„å›¾" in response_text:
        um_score += 3
        print("âœ… åŒ…å«é™„å›¾è¯´æ˜")

    scores["å®ç”¨æ–°å‹ç‰¹å¾"] = min(um_score, 20)

    # æ€»åˆ†
    total_score = sum(scores.values())

    print(f"\n{'='*70}")
    print(f"ğŸ“ˆ è¯„åˆ†ç»“æœ")
    print(f"{'='*70}")
    for category, score in scores.items():
        weight = SCORING_CRITERIA[category]["weight"]
        print(f"{category:15s} {score:5.1f}/{weight}åˆ†")
    print(f"{'-'*70}")
    print(f"{'æ€»åˆ†':15s} {total_score:5.1f}/100åˆ†")
    print(f"{'='*70}")

    return {
        "test_case": test_case_name,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "scores": scores,
        "total_score": total_score,
        "response_length": len(response_text),
        "status": "é€šè¿‡" if total_score >= 90 else "éœ€æ”¹è¿›"
    }

async def run_legal_compliance_tests():
    """è¿è¡Œæ³•è§„åˆè§„æ€§æµ‹è¯•"""
    print("\n" + "="*70)
    print("ğŸ§ª å®ç”¨æ–°å‹ä¸“åˆ©Agent - æ³•è§„åˆè§„æ€§æµ‹è¯•")
    print("="*70)

    test_results = []

    # æµ‹è¯•1ï¼šæ‹’ç»è½¯ä»¶ä¸“åˆ©ç”³è¯·
    print("\n" + "="*70)
    print("æµ‹è¯•1ï¼šæ‹’ç»è½¯ä»¶ä¸“åˆ©ç”³è¯·")
    print("="*70)

    result = await Runner.run(
        utility_model_agent,
        "è¯·æ’°å†™ä¸€ä»½è½¯ä»¶ä¸“åˆ©ï¼šåŸºäºAIçš„æ™ºèƒ½æ¨èç®—æ³•"
    )

    test1_result = evaluate_response(result.final_output, "æ‹’ç»è½¯ä»¶ä¸“åˆ©")
    test_results.append(test1_result)

    # æµ‹è¯•2ï¼šæ‹’ç»æ–¹æ³•ä¸“åˆ©ç”³è¯·
    print("\n" + "="*70)
    print("æµ‹è¯•2ï¼šæ‹’ç»æ–¹æ³•ä¸“åˆ©ç”³è¯·")
    print("="*70)

    result = await Runner.run(
        utility_model_agent,
        "è¯·æ’°å†™ä¸€ä»½æ–¹æ³•ä¸“åˆ©ï¼šä¸€ç§æé«˜å·¥ä½œæ•ˆç‡çš„æ–¹æ³•"
    )

    test2_result = evaluate_response(result.final_output, "æ‹’ç»æ–¹æ³•ä¸“åˆ©")
    test_results.append(test2_result)

    # æµ‹è¯•3ï¼šç”Ÿæˆå®ä½“äº§å“ä¸“åˆ©ï¼ˆç¬¦åˆè¦æ±‚ï¼‰
    print("\n" + "="*70)
    print("æµ‹è¯•3ï¼šç”Ÿæˆå®ä½“äº§å“ä¸“åˆ©")
    print("="*70)

    result = await Runner.run(
        utility_model_agent,
        """
        è¯·æ’°å†™ä¸€ä»½å®ç”¨æ–°å‹ä¸“åˆ©ï¼š

        äº§å“åç§°ï¼šä¸€ç§ä¾¿äºæºå¸¦çš„æŠ˜å å¼æ”¶çº³ç›’
        æŠ€æœ¯é¢†åŸŸï¼šæ—¥å¸¸ç”Ÿæ´»ç”¨å“ã€æ”¶çº³å®¹å™¨
        äº§å“ç»“æ„ï¼šç›’ä½“ã€æŠ˜å é“°é“¾ã€å¡æ‰£å›ºå®šè£…ç½®ã€ä¾§å£åŠ å¼ºç­‹
        ç‰¹ç‚¹ï¼š
        - æŠ˜å è®¾è®¡ä¾¿äºæºå¸¦å’Œå­˜å‚¨
        - å¡æ‰£å›ºå®šä¿è¯å±•å¼€åç¨³å›ºæ€§
        - ä¾§å£åŠ å¼ºç­‹æé«˜æ‰¿é‡èƒ½åŠ›
        """
    )

    test3_result = evaluate_response(result.final_output, "å®ä½“äº§å“ä¸“åˆ©")
    test_results.append(test3_result)

    # æµ‹è¯•4ï¼šåˆ›æ–°æ€§äº§å“ä¸“åˆ©
    print("\n" + "="*70)
    print("æµ‹è¯•4ï¼šåˆ›æ–°æ€§äº§å“ä¸“åˆ©")
    print("="*70)

    result = await Runner.run(
        utility_model_agent,
        """
        è¯·æ’°å†™ä¸€ä»½å®ç”¨æ–°å‹ä¸“åˆ©ï¼š

        äº§å“åç§°ï¼šä¸€ç§é˜²æ»‘æŠ˜å æ¢¯å­
        æŠ€æœ¯é¢†åŸŸï¼šæ¢¯å­è®¾å¤‡ã€å»ºç­‘è¾…åŠ©å·¥å…·
        äº§å“ç»“æ„ï¼šæ¢¯ä½“ã€è¸æ¿ã€é˜²æ»‘å«ç‰‡ã€æŠ˜å æœºæ„ã€å®‰å…¨é”æ‰£ã€ä¼¸ç¼©æ”¯æ’‘æ†
        åˆ›æ–°ç‚¹ï¼š
        - è¸æ¿è¡¨é¢å¢åŠ é˜²æ»‘çº¹ç†è®¾è®¡
        - æŠ˜å æœºæ„é‡‡ç”¨åŒå‘é”å®šæœºåˆ¶
        - åº•éƒ¨å¢åŠ å¯è°ƒèŠ‚æ”¯æ’‘è„š
        - æ•´ä½“é‡‡ç”¨è½»é‡åŒ–ææ–™ä½†ä¿æŒå¼ºåº¦
        """
    )

    test4_result = evaluate_response(result.final_output, "åˆ›æ–°æ€§äº§å“ä¸“åˆ©")
    test_results.append(test4_result)

    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    print("\n" + "="*70)
    print("ğŸ“‹ ç»¼åˆæµ‹è¯•æŠ¥å‘Š")
    print("="*70)

    avg_score = sum(r["total_score"] for r in test_results) / len(test_results)

    print(f"\næµ‹è¯•æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æµ‹è¯•ç”¨ä¾‹æ•°ï¼š{len(test_results)}")
    print(f"å¹³å‡å¾—åˆ†ï¼š{avg_score:.1f}/100åˆ†")

    passed = sum(1 for r in test_results if r["status"] == "é€šè¿‡")
    print(f"é€šè¿‡ç‡ï¼š{passed}/{len(test_results)} ({(passed/len(test_results)*100):.1f}%)")

    print(f"\n{'='*70}")
    print("è¯¦ç»†ç»“æœï¼š")
    print(f"{'='*70}")

    for i, result in enumerate(test_results, 1):
        print(f"\n{i}. {result['test_case']}")
        print(f"   çŠ¶æ€ï¼š{result['status']}")
        print(f"   å¾—åˆ†ï¼š{result['total_score']:.1f}/100åˆ†")
        print(f"   å­—ç¬¦æ•°ï¼š{result['response_length']}")

    # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
    report_file = f"æ³•è§„åˆè§„æ€§æµ‹è¯•æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("å®ç”¨æ–°å‹ä¸“åˆ©Agent - æ³•è§„åˆè§„æ€§æµ‹è¯•æŠ¥å‘Š\n")
        f.write("="*70 + "\n\n")
        f.write(f"æµ‹è¯•æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æµ‹è¯•ç”¨ä¾‹æ•°ï¼š{len(test_results)}\n")
        f.write(f"å¹³å‡å¾—åˆ†ï¼š{avg_score:.1f}/100åˆ†\n")
        f.write(f"é€šè¿‡ç‡ï¼š{passed}/{len(test_results)} ({(passed/len(test_results)*100):.1f}%)\n\n")

        f.write("="*70 + "\n")
        f.write("è¯¦ç»†è¯„åˆ†ï¼š\n")
        f.write("="*70 + "\n")

        for i, result in enumerate(test_results, 1):
            f.write(f"\n{i}. {result['test_case']}\n")
            f.write(f"   çŠ¶æ€ï¼š{result['status']}\n")
            f.write(f"   å¾—åˆ†ï¼š{result['total_score']:.1f}/100åˆ†\n")
            f.write(f"   å­—ç¬¦æ•°ï¼š{result['response_length']}\n")

            for category, score in result["scores"].items():
                weight = SCORING_CRITERIA[category]["weight"]
                f.write(f"   {category}: {score:.1f}/{weight}åˆ†\n")

        f.write("\n" + "="*70 + "\n")
        f.write("æ³•è§„è¦æ±‚æ£€æŸ¥é¡¹ï¼š\n")
        f.write("="*70 + "\n")
        for category, details in SCORING_CRITERIA.items():
            f.write(f"\nã€{category}ã€‘æƒé‡ï¼š{details['weight']}åˆ†\n")
            f.write(f"{details['description']}\n")
            for check in details["checks"]:
                f.write(f"  - {check}\n")

    print(f"\nâœ… æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°ï¼š{report_file}")

    return test_results

if __name__ == "__main__":
    asyncio.run(run_legal_compliance_tests())
