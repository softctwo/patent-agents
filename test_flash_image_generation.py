#!/usr/bin/env python3
"""
ä½¿ç”¨Gemini-2.0-Flash-Preview-Image-Generationæµ‹è¯•å›¾åƒç”Ÿæˆ
å¹¶ä½¿ç”¨OCRè¯„ä¼°ç»˜å›¾è´¨é‡
"""

import os
import sys
import google.generativeai as genai
from datetime import datetime
from PIL import Image
import numpy as np

# è®¾ç½®APIå¯†é’¥
API_KEY = "AIzaSyAPnIWfYq8oGS7yAmNXdP0k8NuPB_gu5VU"
os.environ['GOOGLE_API_KEY'] = API_KEY
genai.configure(api_key=API_KEY)

# å°è¯•å¯¼å…¥OCRåº“
try:
    import easyocr
    OCR_AVAILABLE = True
    print("âœ… EasyOCR å¯ç”¨")
except ImportError:
    OCR_AVAILABLE = False
    print("âš ï¸ EasyOCR ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å…¶ä»–æ–¹æ³•è¯„ä¼°")

def create_patent_drawing_prompt(request):
    """æ„å»ºä¸“åˆ©ç»˜å›¾æç¤ºè¯"""
    prompt = f"""
Create a professional patent technical drawing for: {request.get('invention_title', 'Device')}

SPECIFICATIONS:
- Type: Patent technical drawing (black lines on white background)
- Style: IEEE/ISO standard technical drawing
- Quality: Professional, high precision
- Standard: A4 format (210x297mm at 300 DPI)
- Language: Only English labels and numbers
- NO CHINESE CHARACTERS anywhere

PRODUCT DESCRIPTION:
{request.get('product_description', '')}

KEY COMPONENTS TO DRAW:
"""
    
    for i, comp in enumerate(request.get('key_components', []), 1):
        prompt += f"{i}. {comp}\n"
    
    prompt += """
DRAWING REQUIREMENTS:
1. Use clean, precise black lines only
2. Draw rectangular and circular components as appropriate
3. Add numbered labels (1, 2, 3...) next to each component
4. Use professional technical drawing style
5. Maintain consistent line thickness
6. Show relationships between components with lines
7. Include title: "Figure 1: [Invention Name]"
8. NO shading, NO colors, NO 3D effects
9. Patent drawing standard: clean black lines on white background

IMPORTANT:
- ONLY use English labels and Arabic numerals (1, 2, 3...)
- NO Chinese characters or text
- Follow patent drawing guidelines exactly
- Professional technical illustration style
"""
    
    return prompt

def test_flash_image_generation():
    """æµ‹è¯•Gemini-2.0-Flash-Preview-Image-Generationæ¨¡å‹"""
    print("\n" + "=" * 70)
    print("ğŸ¨ æµ‹è¯•Gemini-2.0-Flash-Preview-Image-Generationæ¨¡å‹")
    print("=" * 70)
    
    # æµ‹è¯•è¯·æ±‚
    request = {
        'invention_title': 'Advanced Smart IoT Sensor Device',
        'product_description': 'An intelligent IoT sensor device with AI processing capabilities, real-time data monitoring, wireless connectivity, and automated control systems for smart environments',
        'key_components': [
            'Central Processing Unit (CPU)',
            'WiFi Communication Module',
            'Temperature Sensor',
            'Humidity Sensor',
            'Light Sensor',
            'Power Management Unit',
            'User Interface (LED Display)',
            'Memory Storage (Flash Memory)',
            'Battery Backup System',
            'Wireless Antenna'
        ]
    }
    
    # æ„å»ºæç¤ºè¯
    prompt = create_patent_drawing_prompt(request)
    
    model_name = 'gemini-2.0-flash-preview-image-generation'
    
    print(f"\nğŸ“¦ æµ‹è¯•æ¨¡å‹: {model_name}")
    print("-" * 70)
    
    try:
        # ä½¿ç”¨generateContentæ–¹æ³•
        model = genai.GenerativeModel(model_name)
        print(f"âœ… æ¨¡å‹ {model_name} åˆå§‹åŒ–æˆåŠŸ")
        
        print("\nğŸ§  æ­£åœ¨ç”Ÿæˆä¸“åˆ©é™„å›¾...")
        response = model.generate_content(
            prompt,
            generation_config={
                "temperature": 0.1,
                "top_p": 0.8,
                "max_output_tokens": 4096,
            }
        )
        
        print("âœ… å›¾åƒç”Ÿæˆè¯·æ±‚å®Œæˆ")
        
        if response.candidates and response.candidates[0].content.parts:
            image_data = None
            for part in response.candidates[0].content.parts:
                if hasattr(part, 'inline_data') and part.inline_data.data:
                    image_data = part.inline_data.data
                    print(f"âœ… æ”¶åˆ°å›¾åƒæ•°æ®: {len(image_data)} bytes")
                    break
            
            if image_data:
                # ä¿å­˜å›¾åƒ
                output_file = f"flash_image_generated_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                with open(output_file, 'wb') as f:
                    f.write(image_data)
                
                print(f"âœ… å›¾åƒå·²ä¿å­˜: {output_file}")
                return output_file, image_data
            else:
                print("âŒ å“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®")
                return None, None
        else:
            print("âŒ å“åº”ä¸­æ²¡æœ‰æœ‰æ•ˆå†…å®¹")
            return None, None
    
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def analyze_image_quality(image_path):
    """åˆ†æå›¾åƒè´¨é‡"""
    print(f"\nğŸ” åˆ†æå›¾åƒè´¨é‡: {image_path}")
    print("-" * 70)
    
    try:
        # åŠ è½½å›¾åƒ
        img = Image.open(image_path)
        width, height = img.size
        
        print(f"ğŸ“ å°ºå¯¸: {width} x {height} pixels")
        print(f"ğŸ¨ æ¨¡å¼: {img.mode}")
        
        dpi = img.info.get('dpi')
        if dpi:
            print(f"ğŸ“ DPI: {dpi[0]} x {dpi[1]}")
        else:
            print("ğŸ“ DPI: æœªè®¾ç½®")
        
        # è½¬æ¢ä¸ºç°åº¦å›¾åƒè¿›è¡Œåˆ†æ
        if img.mode != 'L':
            img_gray = img.convert('L')
        else:
            img_gray = img
        
        # è®¡ç®—å›¾åƒç»Ÿè®¡ä¿¡æ¯
        img_array = np.array(img_gray)
        mean_pixel = np.mean(img_array)
        std_pixel = np.std(img_array)
        min_pixel = np.min(img_array)
        max_pixel = np.max(img_array)
        
        print(f"\nğŸ“Š åƒç´ ç»Ÿè®¡:")
        print(f"   å¹³å‡å€¼: {mean_pixel:.2f}")
        print(f"   æ ‡å‡†å·®: {std_pixel:.2f}")
        print(f"   æœ€å°å€¼: {min_pixel}")
        print(f"   æœ€å¤§å€¼: {max_pixel}")
        
        # è®¡ç®—å¯¹æ¯”åº¦
        if max_pixel > min_pixel:
            contrast = (max_pixel - min_pixel) / (max_pixel + min_pixel) * 100
        else:
            contrast = 0
        print(f"   å¯¹æ¯”åº¦: {contrast:.2f}%")
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºé«˜è´¨é‡ä¸“åˆ©é™„å›¾
        print(f"\nğŸ¯ è´¨é‡è¯„ä¼°:")
        is_good_quality = True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºé»‘ç™½å›¾åƒ
        if img.mode in ['L', '1']:
            print(f"   âœ… å›¾åƒæ¨¡å¼: ç¬¦åˆä¸“åˆ©è¦æ±‚ (é»‘ç™½å›¾åƒ)")
        else:
            print(f"   âš ï¸ å›¾åƒæ¨¡å¼: {img.mode} (å»ºè®®ä½¿ç”¨é»‘ç™½å›¾åƒ)")
            is_good_quality = False
        
        # æ£€æŸ¥å°ºå¯¸
        if width >= 2000 and height >= 2000:
            print(f"   âœ… å›¾åƒå°ºå¯¸: ç¬¦åˆé«˜åˆ†è¾¨ç‡è¦æ±‚")
        else:
            print(f"   âš ï¸ å›¾åƒå°ºå¯¸: å¯èƒ½éœ€è¦æ›´é«˜åˆ†è¾¨ç‡")
            is_good_quality = False
        
        # æ£€æŸ¥å¯¹æ¯”åº¦
        if contrast > 20:
            print(f"   âœ… å¯¹æ¯”åº¦: è‰¯å¥½ ({contrast:.2f}%)")
        else:
            print(f"   âš ï¸ å¯¹æ¯”åº¦: å¯èƒ½åä½ ({contrast:.2f}%)")
        
        # OCRè¯†åˆ«ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        ocr_results = None
        if OCR_AVAILABLE:
            print(f"\nğŸ”¤ OCRæ–‡æœ¬è¯†åˆ«:")
            try:
                reader = easyocr.Reader(['en'])
                results = reader.readtext(image_path)
                
                if results:
                    print(f"   âœ… è¯†åˆ«åˆ° {len(results)} ä¸ªæ–‡æœ¬åŒºåŸŸ:")
                    english_texts = []
                    for (bbox, text, confidence) in results[:10]:
                        if confidence > 0.5 and text.strip():
                            english_texts.append(text.strip())
                            print(f"      - '{text}' (ç½®ä¿¡åº¦: {confidence:.2f})")
                    
                    if english_texts:
                        print(f"\nğŸ“ è¯†åˆ«åˆ°çš„è‹±æ–‡æ–‡æœ¬:")
                        print(f"   {' '.join(english_texts)}")
                        ocr_results = english_texts
                else:
                    print(f"   âš ï¸ æœªè¯†åˆ«åˆ°æ–‡æœ¬")
            except Exception as e:
                print(f"   âŒ OCRè¯†åˆ«å¤±è´¥: {e}")
        
        return {
            'width': width,
            'height': height,
            'mode': img.mode,
            'dpi': dpi,
            'mean_pixel': mean_pixel,
            'std_pixel': std_pixel,
            'contrast': contrast,
            'is_good_quality': is_good_quality,
            'ocr_results': ocr_results
        }
        
    except Exception as e:
        print(f"âŒ å›¾åƒåˆ†æå¤±è´¥: {e}")
        return None

def compare_with_existing_images():
    """æ¯”è¾ƒä¸ç°æœ‰çš„AIç”Ÿæˆçš„å›¾åƒ"""
    print("\n" + "=" * 70)
    print("ğŸ“Š æ¯”è¾ƒç°æœ‰AIç”Ÿæˆçš„ä¸“åˆ©é™„å›¾")
    print("=" * 70)
    
    # æŸ¥æ‰¾ç°æœ‰çš„AIç»˜å›¾
    existing_images = [
        'openai-agents-python/examples/patent_agent/gemini_intelligent_20251030_032052.png',
        'openai-agents-python/examples/patent_agent/ai_test_mechanical.png',
        'openai-agents-python/examples/patent_agent/ai_test_circuit.png'
    ]
    
    print("\nğŸ” åˆ†æç°æœ‰å›¾åƒ:")
    for img_path in existing_images:
        if os.path.exists(img_path):
            print(f"\nğŸ“ {os.path.basename(img_path)}")
            quality = analyze_image_quality(img_path)
            if quality:
                print(f"   è´¨é‡ç­‰çº§: {'âœ… ä¼˜ç§€' if quality['is_good_quality'] else 'âš ï¸ ä¸€èˆ¬'}")
        else:
            print(f"\nâŒ æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")

def main():
    print("=" * 70)
    print("ğŸ¨ Gemini-2.0-Flash-Preview-Image-Generation + OCR æµ‹è¯•")
    print("=" * 70)
    print(f"â° æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æµ‹è¯•Gemini-2.0-Flash-Preview-Image-Generationæ¨¡å‹
    generated_image, image_data = test_flash_image_generation()
    
    if generated_image:
        # åˆ†æç”Ÿæˆçš„å›¾åƒ
        print("\n" + "=" * 70)
        print("ğŸ“Š æ–°ç”Ÿæˆå›¾åƒè´¨é‡åˆ†æ")
        print("=" * 70)
        
        quality = analyze_image_quality(generated_image)
        
        if quality:
            print("\n" + "=" * 70)
            print("ğŸ“‹ æœ€ç»ˆè¯„ä¼°æŠ¥å‘Š")
            print("=" * 70)
            
            print(f"\nâœ… æ¨¡å‹çŠ¶æ€: Gemini-2.0-Flash-Preview-Image-Generation")
            print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶: {generated_image}")
            print(f"ğŸ’¾ æ–‡ä»¶å¤§å°: {len(image_data):,} bytes")
            
            print(f"\nğŸ¯ å›¾åƒè´¨é‡:")
            print(f"   å°ºå¯¸: {quality['width']} x {quality['height']}")
            print(f"   æ¨¡å¼: {quality['mode']}")
            print(f"   å¯¹æ¯”åº¦: {quality['contrast']:.2f}%")
            print(f"   ç»¼åˆè¯„çº§: {'âœ… ä¼˜ç§€' if quality['is_good_quality'] else 'âš ï¸ ä¸€èˆ¬'}")
            
            if quality['ocr_results']:
                print(f"\nğŸ”¤ OCRè¯†åˆ«ç»“æœ:")
                print(f"   è¯†åˆ«åˆ°è‹±æ–‡æ–‡æœ¬: {len(quality['ocr_results'])} ä¸ª")
                for text in quality['ocr_results']:
                    print(f"      - {text}")
    else:
        print("\nâŒ å›¾åƒç”Ÿæˆå¤±è´¥")
    
    # æ¯”è¾ƒç°æœ‰å›¾åƒ
    compare_with_existing_images()
    
    print("\n" + "=" * 70)
    print("ğŸ“ æ€»ç»“ä¸å»ºè®®")
    print("=" * 70)
    print("\n1. âœ… Gemini-2.0-Flash-Preview-Image-Generation æ¨¡å‹å¯ç”¨äºå›¾åƒç”Ÿæˆ")
    print("2. ğŸ“ ç”Ÿæˆçš„å›¾åƒè´¨é‡éœ€è¦è¿›ä¸€æ­¥éªŒè¯")
    print("3. ğŸ” OCRå¯ç”¨äºè¯„ä¼°å›¾åƒä¸­çš„æ–‡æœ¬æ ‡è®°")
    print("4. ğŸ’¡ å»ºè®®:")
    print("   - ä½¿ç”¨Gemini-2.5-Proç”Ÿæˆæ™ºèƒ½ç»˜å›¾æ–¹æ¡ˆ")
    print("   - ç”¨Pythonæ¸²æŸ“ç”Ÿæˆé«˜è´¨é‡ä¸“åˆ©é™„å›¾")
    print("   - ç»“åˆOCRéªŒè¯æ–‡æœ¬æ ‡è®°è´¨é‡")

if __name__ == "__main__":
    main()

